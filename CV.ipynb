{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "datagen = ImageDataGenerator(\n",
    "        )\n",
    "\n",
    "I = np.load('s_x_train.npy')\n",
    "L = np.load('s_y_train.npy')\n",
    "label_count = 0 \n",
    "for x in I:\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "\n",
    "    if(L[label_count] == 0):\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir='test/nodefect', save_prefix='nodefect', save_format='jpeg'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir='test/defect', save_prefix='defect', save_format='jpeg'):\n",
    "            break\n",
    "    label_count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 7s 424ms/step - loss: 0.7887 - accuracy: 0.5273 - val_loss: 0.7307 - val_accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.6849 - accuracy: 0.5977 - val_loss: 0.6373 - val_accuracy: 0.8750\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.6400 - accuracy: 0.6406 - val_loss: 0.6409 - val_accuracy: 0.7083\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.5868 - accuracy: 0.7461 - val_loss: 0.3943 - val_accuracy: 0.7812\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.5212 - accuracy: 0.7734 - val_loss: 0.2712 - val_accuracy: 0.9167\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.4862 - accuracy: 0.7891 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.4579 - accuracy: 0.7852 - val_loss: 0.4600 - val_accuracy: 0.8438\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.4641 - accuracy: 0.7930 - val_loss: 0.4640 - val_accuracy: 0.7917\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.4563 - accuracy: 0.8164 - val_loss: 0.1791 - val_accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.4082 - accuracy: 0.8516 - val_loss: 0.3007 - val_accuracy: 0.9062\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.4280 - accuracy: 0.8398 - val_loss: 0.3382 - val_accuracy: 0.7917\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.3836 - accuracy: 0.8398 - val_loss: 0.3000 - val_accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 0.3408 - accuracy: 0.8555 - val_loss: 0.3510 - val_accuracy: 0.8438\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.3403 - accuracy: 0.8555 - val_loss: 0.2402 - val_accuracy: 0.9167\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.3267 - accuracy: 0.8711 - val_loss: 0.1420 - val_accuracy: 0.8750\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 0.3211 - accuracy: 0.8594 - val_loss: 0.2311 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.2824 - accuracy: 0.8984 - val_loss: 0.2639 - val_accuracy: 0.8750\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.2821 - accuracy: 0.8594 - val_loss: 0.4191 - val_accuracy: 0.8750\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.2666 - accuracy: 0.8984 - val_loss: 0.1280 - val_accuracy: 0.8750\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 0.2709 - accuracy: 0.8984 - val_loss: 0.2338 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.2905 - accuracy: 0.8672 - val_loss: 0.2166 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.2099 - accuracy: 0.9062 - val_loss: 0.3523 - val_accuracy: 0.8750\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 4s 278ms/step - loss: 0.2401 - accuracy: 0.9102 - val_loss: 0.1582 - val_accuracy: 0.9583\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.2874 - accuracy: 0.9062 - val_loss: 0.5322 - val_accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.2595 - accuracy: 0.9062 - val_loss: 0.2284 - val_accuracy: 0.9062\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.2089 - accuracy: 0.8945 - val_loss: 0.2652 - val_accuracy: 0.8333\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.2652 - accuracy: 0.8828 - val_loss: 0.2550 - val_accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 0.2302 - accuracy: 0.9062 - val_loss: 0.0641 - val_accuracy: 0.9375\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.2130 - accuracy: 0.9062 - val_loss: 0.2041 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.2239 - accuracy: 0.9141 - val_loss: 0.3066 - val_accuracy: 0.9167\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.1906 - accuracy: 0.9102 - val_loss: 0.2713 - val_accuracy: 0.8438\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.1822 - accuracy: 0.9219 - val_loss: 0.2605 - val_accuracy: 0.9167\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.2184 - accuracy: 0.9141 - val_loss: 0.1467 - val_accuracy: 0.7917\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.1725 - accuracy: 0.9336 - val_loss: 0.2767 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1875 - accuracy: 0.9336 - val_loss: 0.1431 - val_accuracy: 0.9167\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.1743 - accuracy: 0.9219 - val_loss: 0.2799 - val_accuracy: 0.9167\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 0.2165 - accuracy: 0.9062 - val_loss: 0.3889 - val_accuracy: 0.8750\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 4s 278ms/step - loss: 0.1563 - accuracy: 0.9414 - val_loss: 0.1840 - val_accuracy: 0.9167\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.1730 - accuracy: 0.9180 - val_loss: 0.4215 - val_accuracy: 0.9167\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 0.1631 - accuracy: 0.9258 - val_loss: 0.1989 - val_accuracy: 0.8750\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.1648 - accuracy: 0.9297 - val_loss: 0.0798 - val_accuracy: 0.9583\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.1702 - accuracy: 0.9414 - val_loss: 0.1050 - val_accuracy: 0.8750\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1461 - accuracy: 0.9531 - val_loss: 0.0722 - val_accuracy: 0.9375\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1691 - accuracy: 0.9180 - val_loss: 0.2093 - val_accuracy: 0.8750\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 4s 278ms/step - loss: 0.1307 - accuracy: 0.9453 - val_loss: 0.0033 - val_accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.1476 - accuracy: 0.9492 - val_loss: 0.0639 - val_accuracy: 0.8438\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.1231 - accuracy: 0.9531 - val_loss: 0.2505 - val_accuracy: 0.9167\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.1731 - accuracy: 0.9375 - val_loss: 0.2928 - val_accuracy: 0.8750\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1758 - accuracy: 0.9375 - val_loss: 0.2624 - val_accuracy: 0.8438\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.1500 - accuracy: 0.9453 - val_loss: 0.3255 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 256\n",
    "nb_validation_samples = 40\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('pcb_defect_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4238 images belonging to 2 classes.\n",
      "265/265 [==============================] - 19s 72ms/step\n",
      "test loss, test acc: [0.3725375533103943, 0.8397828936576843]\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data/test'\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir, target_size=(img_width, img_height),batch_size=batch_size,class_mode='binary')\n",
    "results = model.evaluate(test_generator,verbose=1)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn_learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-75e6abcfcf54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merror_rate\u001b[0m \u001b[0;31m# 1 - accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# learn = create_cnn(data, models.resnet34, metrics=[accuracy])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_learner' is not defined"
     ]
    }
   ],
   "source": [
    "data = 'data/train'\n",
    "\n",
    "from fastai.metrics import error_rate # 1 - accuracy\n",
    "# learn = create_cnn(data, models.resnet34, metrics=[accuracy])\n",
    "learner = cnn_learner(data, models.resnet18, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
